{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get DenseNet bottleneck features with pretrained model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_files  \n",
    "from keras.preprocessing import image \n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Convert image paths to torch variables\n",
    "# i.e., 'channel' is the 2nd dimention, not the last\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "def path_to_tonsor(img_path):\n",
    "    img = image.load_img(img_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return preprocess(img).unsqueeze(0)\n",
    "\n",
    "def paths_to_tonsor(img_paths):\n",
    "    list_of_tonsors = [path_to_tonsor(img_path) for img_path in img_paths]\n",
    "    tonsors = torch.cat(list_of_tonsors, 0)\n",
    "    variable = Variable(tonsors)\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use Densenet from torchvision.models \n",
    "# load the model together with its pretrained weights\n",
    "from torchvision.models import densenet161\n",
    "densenet161 = densenet161(pretrained = True)\n",
    "# remove last fully-connected layer\n",
    "new_classifier = nn.Sequential(*list(densenet161.classifier.children())[:-1])\n",
    "densenet161.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pass forward the images to get the bottleneck feature maps\n",
    "\n",
    "Due to the limit capacity of my laptop, passing too many images to the DenseNet network at once would stop the kernel. So I send each time a batch of 100 images, save the results in a temporary folder, then restart the kernel for the next batch. After doing this for 67 (9 and 9 respectively) times, for the train set (validation set and test set respectively), I got all the feature maps needed and concatenating them respectively gives the three *.npy* files in the directory of *bottleneck_features*, namely, *DogDenseNet_train*, *DogDenseNet_valid* and *DogDenseNet_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "testBatch_tonsors = paths_to_tonsor(test_files[800:])\n",
    "testBatch_DenseNet = densenet161.forward(testBatch_tonsors)\n",
    "np.save('TestFeatureBatchs/Batch9.npy', testBatch_DenseNet.data.numpy())\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DogDenseNet_test = np.load('TestFeatureBatchs/Batch1.npy')\n",
    "for i in range(2, 10):\n",
    "    DogDenseNet_test = np.concatenate((DogDenseNet_test, np.load('TestFeatureBatchs/Batch'+str(i)+'.npy')))\n",
    "np.save('bottleneck_features/DogDenseNet_test.npy', DogDenseNet_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Now do the same *withOUT* PyTorch, since PyTorch cannot be used on a Window machine\n",
    "\n",
    "I found the following implementations of DenseNet in Keras:\n",
    "\n",
    "* The model in [repository](https://github.com/flyyufelix/DenseNet-Keras.git), stopped at the weight loading stage, due to errors saying that dimensions do not match. \n",
    "* The model in [repository](https://github.com/titu1994/DenseNet.git) can successfully return bottleneck feature maps after modifications:\n",
    "    - was: ~~requie_flatten = include_top~~\n",
    "    + is : include_top = include_top\n",
    "    - was: ~~default_size = 32~~\n",
    "    + is : default_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for the model were loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import densenet\n",
    "\n",
    "image_dim = (224, 224, 3)\n",
    "DenseNet_second = densenet.DenseNetImageNet161(input_shape=image_dim, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2208)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "DenseNet_second.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "DenseNet_output = DenseNet_second.predict(path_to_tensor('images/American_water_spaniel_00648.jpg'))\n",
    "print(DenseNet_output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
