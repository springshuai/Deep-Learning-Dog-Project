{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get DenseNet bottleneck features with pretrained model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_files  \n",
    "from keras.preprocessing import image \n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import densenet161\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Convert image paths to torch variables\n",
    "# i.e., 'channel' is the 2nd dimention, not the last\n",
    "\n",
    "def load_dataset(directory):\n",
    "    data = load_files(directory)\n",
    "    file_paths = np.array(data['filenames'])\n",
    "    file_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return file_paths, file_targets\n",
    "\n",
    "def path_to_tonsor(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                             std = [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    output = preprocess(img).unsqueeze(0)\n",
    "    return output\n",
    "\n",
    "def paths_to_variables(img_paths):\n",
    "    list_of_tonsors = [path_to_tonsor(img_path) for img_path in img_paths]\n",
    "    tonsors = torch.cat(list_of_tonsors, 0)\n",
    "    variables = Variable(tonsors, requires_grad=False)\n",
    "    return variables\n",
    "\n",
    "def paths_to_features(img_paths):\n",
    "    variables = paths_to_variables(img_paths)\n",
    "    \n",
    "    densenet = densenet161(pretrained = True)\n",
    "    new_classifier = nn.Sequential(*list(densenet.classifier.children())[:-1])\n",
    "    densenet.classifier = new_classifier\n",
    "    densenet.eval()\n",
    "    features = densenet.forward(variables)      \n",
    "    return features.data.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pass forward the images to get the bottleneck feature maps\n",
    "\n",
    "Due to the limit capacity of my laptop, passing too many images to the DenseNet network at once would stop the kernel. So I send each time a batch of 100 images, save the features in a temporary folder, repeat untill all features are obtained. After doing this for 67 (9 and 9 respectively) times, for the train set (validation set and test set respectively), I got all the feature maps needed and concatenating them respectively gives the three *.npy* files in the directory of *bottleneck_features*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Now do the same *withOUT* PyTorch, since PyTorch cannot be used on a Window machine\n",
    "\n",
    "I found the following implementations of DenseNet in Keras:\n",
    "\n",
    "* The model in [repository](https://github.com/flyyufelix/DenseNet-Keras.git), stopped at the weight loading stage, due to errors saying that dimensions do not match. \n",
    "* The model in [repository](https://github.com/titu1994/DenseNet.git) can successfully return bottleneck feature maps after modifications:\n",
    "    - was: ~~requie_flatten = include_top~~\n",
    "    + is : include_top = include_top\n",
    "    - was: ~~default_size = 32~~\n",
    "    + is : default_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for the model were loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import densenet\n",
    "\n",
    "image_dim = (224, 224, 3)\n",
    "DenseNet_second = densenet.DenseNetImageNet161(input_shape=image_dim, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_files  \n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def load_dataset(directory):\n",
    "    data = load_files(directory)\n",
    "    file_paths = np.array(data['filenames'])\n",
    "    file_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return file_paths, file_targets\n",
    "train_file_paths, train_file_targets = load_dataset('dogImages/train')\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "       \n",
    "    return densenet.preprocess_input(np.expand_dims(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward the images to get the bottleneck features, in batchs\n",
    "for i in range(1, 67):\n",
    "    path_slice = train_file_paths[(i-1)*100:i*100]\n",
    "    DenseNet_output = [DenseNet_second.predict(path_to_tensor(path)) for path in path_slice]\n",
    "    np.save('bottleneck_features/train/train_batch_'+str(i)+'.npy', DenseNet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DenseNetFeature_test = np.load('bottleneck_features/test/test_batch_1.npy')\n",
    "for i in range(2, 10):\n",
    "    DenseNetFeature_test = np.concatenate((DenseNetFeature_test, \n",
    "                                            np.load('bottleneck_features/test/test_batch_'+str(i)+'.npy')))\n",
    "np.save('bottleneck_features/DenseNetFeature_test.npy', DenseNetFeature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('bottleneck_features/train_DenseNet.npy', DenseNetFeature_train.reshape(6680, 2208))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
